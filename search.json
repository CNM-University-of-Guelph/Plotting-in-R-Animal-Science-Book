[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Plotting in R for Animal Science Workshop",
    "section": "",
    "text": "This online ‘book’ contains a crash-course for animal scientists wanting to efficiently visualise their data, and is designed to accompany an in-person workshop. Therefore, not all of the basics of using R are written here. There are many, better, resources for learning R properly.\nThis book also does not cover statistics, but focuses on data wrangling and plotting.\nThe techniques presented throughout are designed to encourage the reproducibility of work. By keeping well-document codes that do something to our data, we can easily re-create our scientific outputs from the original, raw data."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Plotting in R for Animal Science Workshop",
    "section": "Course outline:",
    "text": "Course outline:\n\n\n\n\n\n\n\n9:00 to 12:00\n\nIntro to visualisations\nIntro to RStudio and R\nData wrangling\nSummarising data\nCreating your first plot\nCustomising your first plot\n\n\n\n12:00 to 13:00\nLunch break\n\n\n13:00 to 16:00\n\nPractice different plot types:\n\nHistograms\nContinuous y-axis with treatment on x-axis:\n\nBox plots\nViolin plots\nBar/column plots with error bars\n\nContinuous x- and y-axis:\n\nScatter plots and trend lines\n\n\nSaving publication-ready plots\nCreate your own plots from own data\nIntro to more advanced plotting techniques:\n\nUsing functions to automate plotting\nInteractive plots\nCorrelations\nHeatmaps\nPrincipal Component Analysis"
  },
  {
    "objectID": "index.html#key-resources",
    "href": "index.html#key-resources",
    "title": "Plotting in R for Animal Science Workshop",
    "section": "Key resources",
    "text": "Key resources\n\nhttps://r4ds.hadley.nz/\nhttps://r-graphics.org/index.html\nhttps://r-graph-gallery.com/index.html\nhttps://ourcodingclub.github.io/tutorials.html\nhttps://exts.ggplot2.tidyverse.org/gallery/"
  },
  {
    "objectID": "intro.html#using-projects",
    "href": "intro.html#using-projects",
    "title": "1  Getting Started in Rstudio",
    "section": "1.1 Using Projects",
    "text": "1.1 Using Projects\nIt is best to use a Project for any data analysis within the RStudio IDE.\nUsing projects has many benefits as multiple related files are all stored in one directory, and this becomes the ‘working directory’ which allows easy use of relative pathways.\nTo begin this workshop we will create a new project. Use the Create Project command (available on the Projects menu and on the global toolbar). Then select ‘Create project from: New Directory’, ’Project Type: New Project’ and call it something like ‘R Plotting Workshop’. This will create a new folder on your computer with this name, so save it somewhere familiar to yourself.\nFor comprehensive help see: https://support.rstudio.com/hc/en-us/articles/200526207-Using-RStudio-Projects\n\n\n\n\n\n\nA note on file paths\n\n\n\nWhen we come to importing or exporting files we will deal with file paths. One of the key benefits of using a project is that it makes relative file paths easier to use.\nAll file paths within a project are relative to the location of the .Rproj file. Therefore if we specify file = 'filename.csv'in a function, it will look in the same folder that your .Rproj file is located.\nWe can also specify that with \"./\" before the file name ( `file = './filename.csv' )where the dot represents the current level and is handy to remind yourself that it is a relative file path. It is also possible to use \"../\" to go up 2 levels, if needed."
  },
  {
    "objectID": "intro.html#using-r-notebooks",
    "href": "intro.html#using-r-notebooks",
    "title": "1  Getting Started in Rstudio",
    "section": "1.2 Using R Notebooks",
    "text": "1.2 Using R Notebooks\nIt is also encouraged that R Notebooks are used (file extension .Rmd) and these should be saved in the top level of the project folder. When you save a Notebook, a .html file is generated in the same folder as the .Rmd file which shows the output of scripts below each ‘chunk’ of code. This will help you keep track of your work and the .html reports make it quick and easy to view the results outside of RStudio. In fact, this book is written in a very similar way to R Notebooks, and you will see why this is so handy in the next chapters.\nOnly the output that is visible when you save or ‘Preview’ the file is saved in the .html file, so acts just like a notebook.\n\n\n\n\n\n\nNote\n\n\n\nThese are different to ‘RMarkdown’ files which executes all of the code at the time of ‘rendering’, despite both using the .Rmd file extension. The output: html_notebook at the start of the file tells RStudio to show the ‘Preview’ button instead of the ‘Render’ option used in RMarkdown files.\n\n\nFor this workshop, let’s create a new R Notebook by clicking File -> New File -> R Notebook. It will bring up some more introductory details if you are unfamiliar with these.\nFiles created in ‘Markdown’ are highly customisable. Some key syntax:\nItalicise Text using italic or _italic_\nBold Text using **bold** or __bold__\nHeading levels:\n\n# Heading 1\n## Heading 2 , etc.\n\nUnordered lists:\n* Item 1\n* Item 2\n    + Item 2a\n    + Item 2b\nOrdered lists:\n1. Item 1\n2. Item 2\n3. Item 3\n    + Item 3a\n    + Item 3b\nMore details: https://rmarkdown.rstudio.com/authoring_basics.html"
  },
  {
    "objectID": "intro.html#installing-packages",
    "href": "intro.html#installing-packages",
    "title": "1  Getting Started in Rstudio",
    "section": "1.3 Installing packages",
    "text": "1.3 Installing packages\nWe will be using ‘packages’ which are basically a group of functions packaged up together with some documentation. When you install and open R (either in RStudio or elsewhere) it pre-loads some base packages.\nLearning base R functions is very important if you continue to use R, especially knowledge of data types (vectors, lists, dataframes, etc), subsetting operations, loops and vectorised operations. This is all outside the scope of this workshop. Although you will be able to follow along with this course, you’ll need to learn some of these concepts to fully utilise R moving forward.\nFor this workshop we will use the `tidyverse`. The tidyverse is a collection of packages that all follow a particular style of coding. It is very well documented and user-friendly, and includes the ggplot2 package, which is the most common way of plotting in R now.\nSee: https://www.tidyverse.org/\nTo install a package, copy and paste this code into the Console and run it.\n\ninstall.packages('tidyverse')\n\n\n\n\n\n\n\nTip\n\n\n\nRStudio also has a ‘Packages’ tab where you can see the packages that are installed and loaded. There’s also an ‘Install’ button which does the same as writing install.packages.\n\n\nWe will also use a dataset collected at Palmer Station, Antarctica about penguins. It is made available in this package :\n\ninstall.packages(\"palmerpenguins\")"
  },
  {
    "objectID": "intro.html#load-packages",
    "href": "intro.html#load-packages",
    "title": "1  Getting Started in Rstudio",
    "section": "1.4 Load packages",
    "text": "1.4 Load packages\nAlthough packages are installed, not all of them are loaded and ready to use. Instead, every time you open your R session you will need to re-load these packages. This is useful, because often you will only want to load certain packages to do a task, not all of them.\nFor the start of this workshop we can simply load the tidyverse, which includes most packages we will use. Copy this code into your own file and follow along.\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nTip\n\n\n\nAll code chunks will have a ‘copy to clipboard’ button appear to the right of the chunk if you hover it.\n\n\nThe first ‘code chunk’ of your R Notebook should be labelled setup, by using {r setup} at the start of code chunk. Everything between the two sets of three backticks (```) is executed as R code, and everything outside of these is rendered as text. By labelling the first code chunk as setup, RStudio will execute this code chunk before running any other code if it has not already done so in the current session. This is particularly useful for loading your R packages.\n```{r setup}\nlibrary(tidyverse)\n```"
  },
  {
    "objectID": "intro.html#getting-help",
    "href": "intro.html#getting-help",
    "title": "1  Getting Started in Rstudio",
    "section": "1.5 Getting help",
    "text": "1.5 Getting help\n\n1.5.1 Help\nPackages are required to have documentation, or a ‘help’ files for each function. To access these, put your cursor on the function name and press F1 key. The documentation will show up in the ‘Help’ tab inside RSTudio. Otherwise, type help(functionname) or ?functionnamein the Console. e.g. help(ggplot) or ?functionname.\n\n\n1.5.2 Vignettes\nSome packages also have vignettes, which are long-form documents on how to use a package. The easiest way to find these is to search for the package on CRAN. For example, there are 3 vignette’s listed for the ggplot2 package: https://cran.r-project.org/package=ggplot2\n\n\n1.5.3 Cheat Sheets\nThere are a bunch of cheat sheets for packages available within RStudio ( Help -> Cheat Sheets ->). Also see: https://posit.co/resources/cheatsheets/\n\n\n1.5.4 Search online\nThere’s a lot of resources online for learning R, including free ‘books’ like this one. If you’ve got a particular question you can search on forums like https://stackoverflow.com"
  },
  {
    "objectID": "intro_vis.html#typical-workflow",
    "href": "intro_vis.html#typical-workflow",
    "title": "2  Intro to Data Visualisation",
    "section": "2.1 Typical workflow",
    "text": "2.1 Typical workflow\nA typical workflow might be:\n\nData collection\n\n\nAnimal experiment records (e.g. nice Excel sheets or AirTable sheets/apps)\nData from a machine/instrument in the farm/lab (e.g. sensor data)\n\n\nPrepare data for input to statistical software\n\n\nComputer friendly column names\nBasically any format can be imported. Usually .csv or .txt are easiest for beginners.\n\n\nData wrangling in R\n\n\nwide vs long vs tidy formats\ndates/times and data types\n\n\nData exploration and visualisation\nStatistical Analysis\n\n\nExport clean data to SAS for statistical analysis OR\nrun stats in R\n\n\nImport SAS output (e.g. lsmeans) OR use outputs within R\nCreate publication-ready plots\n\nThere are 2 key steps in this workflow where data visualisation occurs:\n\nData exploration\nCommunicating data"
  },
  {
    "objectID": "intro_vis.html#data-exploration",
    "href": "intro_vis.html#data-exploration",
    "title": "2  Intro to Data Visualisation",
    "section": "2.2 Data exploration",
    "text": "2.2 Data exploration\nData exploration is an important initial process when first looking at a dataset. It’s a time for checking the quality and integrity of your data but also it’s a time to discover things you were not expecting to see.\nVisualisation is key to data exploration, especially when your dataset is very large.\nIt’s also a rough process, and very little time should be spent trying to make your plots visually appealing to others. You may add titles or labels to help you remember what you plot, but you would probably leave many of the default settings. Using a R Notebooks, as we are in this course, are great for this process as you can keep your notes alongside your plots and your code keeps track of exactly what you did.\n\n2.2.1 Example - lactation data\nRecently I noticed some strange numbers when visualising a dataset with daily records for about 800 lactations.\nFirstly, I plotted a count of how many lactations were in the dataset for each day (as a number from 1 to n).\n\nHere we can see that the number of lactations per day decreases over time, which is ok but this was important to know. More importantly, there were some dots displayed between 100 - 200 DIM that did not make sense.\nThis led me to notice this:\n\nIt turns out that 1 cow had some DIM that were not integers e.g. 150.2 which meant they stood out.\nAfter a range of filtering process, the final dataset was visualised and I had a consistent number of records up to 305 DIM… almost. Even this plot showed that there was very few records for less than 10 DIM. In addition, there was 499 lactations but there was never 499 records on any one day, meaning that there must have been some actual dates that had no records.\n\n\n\n2.2.2 Example - comparing ‘means’\nWhen we have experiments with treatments, sometimes we assume all the data is correct and proceed with statistics (and hopefully pick up some outliers in the process) or we just go straight to comparing the means of each treatment visually.\nThis can hide potential problems with your data, but also hides important, real attributes of your data. To take a simple example from the ‘palmer penguins’ dataset. The mean bill depth (mm) for 3 different islands is:\n\n\nCode\n```{r}\n#| code-fold: true\npenguins %>% \n  group_by(island) %>% \n  summarise(mean_bill_depth_mm = mean(bill_depth_mm, na.rm= TRUE))\n```\n\n\n# A tibble: 3 × 2\n  island    mean_bill_depth_mm\n  <fct>                  <dbl>\n1 Biscoe                  15.9\n2 Dream                   18.3\n3 Torgersen               18.4\n\n\nIf we check the raw data, it seems that there’s a lot of overlap, but nothing looks out of place:\n\n\nCode\n```{r}\n#| code-fold: true\nggplot(penguins, aes(x = island, \n                     y = bill_depth_mm, \n                     #colour = species\n                     )) +\n  geom_boxplot()+\n  geom_jitter(width = 0.2)\n```\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nBut if we add looked at an additional variable, we would see that the species itself seems to be important:\n\n\nCode\n```{r}\n#| code-fold: true\nggplot(penguins, aes(x = island, y = bill_depth_mm, colour = species)) +\n  geom_boxplot()\n```\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "intro_vis.html#example---interactive-plots",
    "href": "intro_vis.html#example---interactive-plots",
    "title": "2  Intro to Data Visualisation",
    "section": "2.3 Example - interactive plots",
    "text": "2.3 Example - interactive plots\nOnce we’ve got the hang of building different visualisations to explore our data, we often find ourselves wondering what a 1 particular point on a graph is e.g. an outlier.\nWe can very easily find that data point in a table in R using some filtering OR… we can quickly visualise it interactively so that we can hover over a data point and see some information about it.\n\n\nCode\n```{r}\n#| code-fold: true\n#| warning: false\n#| message: false\nlibrary(plotly)\n\np <- ggplot(penguins, \n            aes(x = island, \n                y = bill_depth_mm, \n                colour = species, \n                text = paste(\"sex: \", sex))\n            ) +\n  geom_jitter()\n\nggplotly(p)\n```\n\n\n\n\n\n\n\n2.3.1 Correlation plots\nHere’s an example of a useful way to explore correlations from https://allisonhorst.github.io/palmerpenguins/articles/pca.html\nNotice the Simpson’s paradox? This is a great example of how correlations alone can be misleading.\n\n\nCode\n```{r}\n#| code-fold: true\n#| warning: false\n#| message: false\n\npenguins %>%\n  select(species, body_mass_g, ends_with(\"_mm\")) %>% \n  GGally::ggpairs(aes(color = species),\n          columns = c(\"flipper_length_mm\", \"body_mass_g\", \n                      \"bill_length_mm\", \"bill_depth_mm\")) \n\n# If you are trying to run this code you will need to install.packages(\"GGally\").\n# \n# The :: in the GGally::ggpairs() above tells R to look for the ggpairs() function within the GGally package, but without loading all of the functions from that package.\n# \n# It is also useful to remind yourself which package a function comes from if it is not something you use often.\n# \n```"
  },
  {
    "objectID": "intro_vis.html#communication-and-publishing",
    "href": "intro_vis.html#communication-and-publishing",
    "title": "2  Intro to Data Visualisation",
    "section": "2.4 Communication and publishing",
    "text": "2.4 Communication and publishing\nAt this point of your workflow you’ve got a good idea about your data and there’s something from it that you want to communicate. There’s a lot of books and resources online, and conflicting opinions about what is best practice.\nVisualisations can be very effective…. or terrible: viz.wtf\n https://viz.wtf/post/673472354894086144/sticking-your-neck-out  \n\n\n\n\n\n\nTip\n\n\n\nCheck out this website to help you rate your data visualisation: https://stephanieevergreen.com/rate-your-visualization/\n\n\nI won’t attempt to explain all there is to know about best practises but have included some relevant resources. Some are even specific to R: http://rafalab.dfci.harvard.edu/dsbook/data-visualization-principles.html\nAs animal scientists we often need to produce visualisations for presentations and for publications, which have different requirements.\nFor example, you won’t see this in a publication but it is effective in drawing attention to your data in a presentation (although there’s still room for improvement with this plot):\n\nFor inspiration and advice for choosing the correct visualisation check out: https://www.data-to-viz.com/\nThere’s also a page on this site that links to certain caveats to watch out for, such as the problems with a dual axis: https://blog.datawrapper.de/dualaxis/\nDid I mention that opinions can differ? Some animal scientistis love these difficult-to-interpet graphs!\nIt just so happens that the authors of ggplot2 dislike dual axis plots and it is therefore inherently difficult to do with ggplot2 (with some exceptions)\n\n2.4.1 Plots for publications\nThere is a whole package dedicated to helping format plots for publications: https://rpkgs.datanovia.com/ggpubr\nFor example, it is great for adding measures of significance (* or P values) to a plot, such as:\n\n\n\n\n\n\n\nNote\n\n\n\nThis is the ggplot part of the code to make the above plot, but it won’t run as a reproducible example. It also won’t make much sense now, but after you finish this course it might!\n\n\nCode\n```{r}\n#| code-fold: true\n#| eval: false\n\np_for_publish<- \n  ggplot(data = data0 , \n         mapping = aes(x = Treatment,\n                       y = column_to_plot,\n                       colour = Treatment)) +\n  geom_blank(aes(x=Treatment, y = y_max0))+\n  geom_boxplot(aes(fill = Treatment))+\n  geom_jitter(aes(fill = Treatment),colour = \"black\", size = 1, width = 0.3, alpha = 0.3, shape = 21)+\n  viridis::scale_color_viridis(discrete=TRUE)+\n  viridis::scale_fill_viridis(discrete=TRUE, alpha = 0.5)+\n  lemon::facet_rep_grid(cols = vars(region), rows = vars(gene_name), repeat.tick.labels ='y', scale = \"free_y\")+\n  xlab(\"Treatment\")+\n  ylab(\"Log2 Expression\")+\n    theme_classic2(base_size = 10) +\n  theme(axis.text.x = element_text(size = 6, colour = \"black\", angle=25, hjust=1),\n        strip.text.x = element_text(size = 8, colour = \"black\", face = \"plain\"),\n        strip.text.y = element_text(size = 8, colour = \"black\", face = \"italic\"), \n        axis.title = element_text(size = 10, colour = \"black\", face = \"plain\"),\n        legend.title = element_text(size = 10, colour = \"black\", face = \"plain\"))+ \n  ggpubr::stat_pvalue_manual(data = data_DE_2 ,\n                             y.position = 'y.position',\n                             label = \"adj-P = {p.adj}\",\n                             label.size = 2.5,\n                             color = \"blue\",\n                             step.group.by = \"region\",\n                             hide.ns=F)\n```\n\n\n\n\n\n\n2.4.2 Plots for anything!\nNearly everything in a plot created with `ggplot2` can be customised. Although this may be tedious at first, it becomes very quick to re-produce high quality plots. We will cover some of these, but if you can think of it, there’s a fair chance someone has already asked about it online!\nI even made the logo for this course using an R package I found after googling some ideas.\n\n\nSee the code for the logo:\n```{r}\n#| code-fold: true\n#| code-summary: \"See the code for the logo:\"\nstring_df1 <- hershey::create_string_df(text = \"Plotting in R\", font = 'futural') %>% mutate(row = 1)\n\nstring_df2 <- hershey::create_string_df(text = \"for Animal Science\", font = 'futural') %>% mutate(row = 2)\n\nstring_df <- bind_rows(string_df1, string_df2)\n\nggplot(string_df, \n       aes(x, y, \n           group = interaction(char_idx, stroke),\n           colour = char,\n           shape = as.factor(row))) +\n  geom_path() +\n  geom_point(size = 1) + \n  coord_equal() +\n  theme(legend.position = 'none')+\n  facet_grid(rows = vars(row))\n```"
  },
  {
    "objectID": "data_wrangling.html#base-r-vs-tidyverse",
    "href": "data_wrangling.html#base-r-vs-tidyverse",
    "title": "3  Data wrangling",
    "section": "3.1 Base R vs tidyverse",
    "text": "3.1 Base R vs tidyverse\nAlthough we will skip of many of the basic R functionality, here is a quick overview of some key features. Based on https://r4ds.hadley.nz/workflow-basics.html#coding-basics\nBasic arithmetic with single numbers:\n\n1 / 200 * 30\n#> [1] 0.15\n\n(59 + 73 + 2) / 3\n#> [1] 44.66667\n\n2^2\n#> [1] 4\n\nsqrt(4)\n#> 2\n\nAssignment operator. This assigns the number to an ‘object name’:\n\n```{r}\nx <- 5 * 2\n\nprint(x)\n```\n\n[1] 10\n\n\nAny object we create in R can be assigned a name, so that it is stored in our Environment for us to access again:\n\nobject_name <- value\n\nWhen reading that code, say “object name gets value” in your head.\n\n\n\n\n\n\nTip\n\n\n\nTo quickly type the assignment operator <- press ALT plus - key (or Option plus - on Mac). Other keyboard shortcuts are listed under Tools -> Keyboard Shortcuts Help.\n\n\nMultiple elements can be combined together into a vector. R will apply functions and arithmetic to the a whole vector. This is a very useful concept in R as we will see when working with data frames (tables).\n\n```{r}\nx <- c(3, 5, 10, 1)\n\nprint(x)\n\nprint(x * 2)\n```\n\n[1]  3  5 10  1\n[1]  6 10 20  2\n\n\nIf we want to access a single element of that vector we can use:\n\n```{r}\nx[1]\n```\n\n[1] 3\n\n\nor multiple elements:\n\n```{r}\n# get values from 1st to 2nd position\nx[1:2]\n\n# use a logical vector:\nx[c(TRUE, TRUE, FALSE, FALSE)]\n\n# or use another vector of positions to return:\nx[c(1,3)]\n```\n\n[1] 3 5\n[1] 3 5\n[1]  3 10\n\n\nLeave a lot of comments in your code! Your future self will love you for it.\n\n```{r}\n# This text is not evaluated by R, because it starts with a hashtag.\n# You can highlight multiple rows of code and press Ctrl + Shift + C to 'comment out' all of them at once.\n```\n\n\n3.1.1 Functions\nFunctions are basically scripts that are designed to take certain inputs, do something useful with those inputs, and then give you something back. They take the form:\n\nfunction_name(argument1 = value1, argument2 = value2, ...)\n\nFor example, the function we used above sqrt() expects 1 argument: ‘a numeric or complex vector or array’. Therefore, we could have written:\n\n```{r}\nsqrt(x = 4)\n\n# because there is only 1 argument, we would typically leave the x = out of it.\nsqrt(4)\n```\n\n[1] 2\n[1] 2\n\n\nEven when we have multiple arguments, we don’t have to write them out in full if we maintain the correct order of arguments. Often it is better to though, so you can easily see what you’re trying to do.\n\n```{r}\nseq(from = 10, to = 30, by = 2)\n\n# same as this, which might be confusing:\n#seq(10, 30, 2) \n```\n\n [1] 10 12 14 16 18 20 22 24 26 28 30\n\n\nSometimes we find functions with ... which means that it will take multiple values in this position.\nFor example, thepaste() function expects ... for it’s first object and the help page says this argument should be: “One or more R objects, to be converted to character vectors”.\nTherefore we can do:\n\n```{r}\npaste(\"Hello\", \"World\")\n\n# OR:\nstring1 <- \"Hello\" \nstring2 <- \"World\"\n\npaste(string1, string2)\n```\n\n[1] \"Hello World\"\n[1] \"Hello World\"\n\n\nBut it still has named arguments we can use:\n\n```{r}\npaste(string1, string2, sep = \"_*_\")\n```\n\n[1] \"Hello_*_World\"\n\n\nWhen we paste a vector with a single value, it will return multiple strings. But we can also request them to be collapsed into 1 string.\n\n```{r}\n# multiple strings:\npaste(x, string1, sep = \"\")\n\n# 1 string:\npaste(x, string1, string2, sep = \"\", collapse = \"_\")\n```\n\n[1] \"3Hello\"  \"5Hello\"  \"10Hello\" \"1Hello\" \n[1] \"3HelloWorld_5HelloWorld_10HelloWorld_1HelloWorld\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you’re working with strings, check out the stringr package."
  },
  {
    "objectID": "data_wrangling.html#create-demo-dataset",
    "href": "data_wrangling.html#create-demo-dataset",
    "title": "3  Data wrangling",
    "section": "3.2 Create demo dataset",
    "text": "3.2 Create demo dataset\nThis code creates a data frame using only numbers and strings (text). This is an example of a ‘reproducible example’ where anybody can take this code, run it and see the same df_data object in their environment.\nThis is also handy for testing code or asking questions online. For more details on reproducible examples see https://www.tidyverse.org/help/#reprex\nYou’ll rarely need to make a data frame from scratch, but it’s handy to see that it is a collection of vectors, where each row is a vector.\n\n```{r}\ndf_data <- data.frame(\n  Animal_ID = rep(c(11,12,21,22), times = 3),\n  Timepoint = rep(seq(from = 1, to = 3), each = 4),\n  Treatment_Group = rep(c(\"Treatment A\",\"Treatment B\"), each = 2, times = 3),\n  Variable = c(1,1.2,1,1.2,2,2.5,.5,.4,3,3.5,0.2,.1))\n```\n\nTo show the dataframe we just created below our code chunk we can write print(df_data) or simply df_data works in RStudio:\n\n```{r}\ndf_data\n```\n\n   Animal_ID Timepoint Treatment_Group Variable\n1         11         1     Treatment A      1.0\n2         12         1     Treatment A      1.2\n3         21         1     Treatment B      1.0\n4         22         1     Treatment B      1.2\n5         11         2     Treatment A      2.0\n6         12         2     Treatment A      2.5\n7         21         2     Treatment B      0.5\n8         22         2     Treatment B      0.4\n9         11         3     Treatment A      3.0\n10        12         3     Treatment A      3.5\n11        21         3     Treatment B      0.2\n12        22         3     Treatment B      0.1\n\n\nThis dataframe can also be viewed in it’s own tab inside RStudio, like an excel sheet. Put your cursor on df_data and press F2 or type:\n\n```{r}\n#| eval: false\nView(df_data) #notice the capital V\n```"
  },
  {
    "objectID": "data_wrangling.html#wide-vs-long-vs-tidy-data",
    "href": "data_wrangling.html#wide-vs-long-vs-tidy-data",
    "title": "3  Data wrangling",
    "section": "3.3 Wide vs Long vs Tidy data",
    "text": "3.3 Wide vs Long vs Tidy data\nOften people consider the shape of a data frame to be either wide or long. Wide data might look like this, where some column names contains values (not headings):\n\n\nCode\n```{r}\n#| code-fold: true\npivot_wider(df_data, \n            names_from = Timepoint, \n            values_from = Variable, \n            names_prefix = \"Time_\")\n```\n\n\n# A tibble: 4 × 5\n  Animal_ID Treatment_Group Time_1 Time_2 Time_3\n      <dbl> <chr>            <dbl>  <dbl>  <dbl>\n1        11 Treatment A        1      2      3  \n2        12 Treatment A        1.2    2.5    3.5\n3        21 Treatment B        1      0.5    0.2\n4        22 Treatment B        1.2    0.4    0.1\n\n\nOr, we might see that information about the same animal is spread across multiple rows in a long format:\n\n\nCode\n```{r}\n#| code-fold: true\npivot_longer(df_data,\n             cols = c(Timepoint, Variable), \n             names_to = 'name', \n             values_to = 'value')\n```\n\n\n# A tibble: 24 × 4\n   Animal_ID Treatment_Group name      value\n       <dbl> <chr>           <chr>     <dbl>\n 1        11 Treatment A     Timepoint   1  \n 2        11 Treatment A     Variable    1  \n 3        12 Treatment A     Timepoint   1  \n 4        12 Treatment A     Variable    1.2\n 5        21 Treatment B     Timepoint   1  \n 6        21 Treatment B     Variable    1  \n 7        22 Treatment B     Timepoint   1  \n 8        22 Treatment B     Variable    1.2\n 9        11 Treatment A     Timepoint   2  \n10        11 Treatment A     Variable    2  \n# … with 14 more rows\n\n\nBut when we made our demo data frame we actually made it in ‘tidy’ format, because the tidyverse is designed to work with data in this format. The principals are best described in the R for Data Science book: https://r4ds.hadley.nz/data-tidy.html#fig-tidy-structure\nWe will often collect observational data in wide format, and present our research in wide format for publications, because it is often the best way for humans to understand data on a page. There are 2 very useful functions for converting your data to a tidy format when you are workign with your data in R: pivot_wider() and pivot_longer(). In fact, that’s the functions used above to swap our original data frame."
  },
  {
    "objectID": "data_wrangling.html#introducing-select-function",
    "href": "data_wrangling.html#introducing-select-function",
    "title": "3  Data wrangling",
    "section": "3.4 Introducing ‘select’ function",
    "text": "3.4 Introducing ‘select’ function\nPicture every function as having an input and output. For example, the basic function paste('hello', 'world') has 2 strings given to it as input, and then when the function is executed it outputs 1 character string, which we can then assign to an object and use later.\nIf we extend this to a function that works on data frames, we would normally give the function a data frame as input and it will return the updated/modified dataframe as output. When using functions from dplyr/tidyverse they always take the input data as the first argument of the function.\nFor example, select() is a function for selecting columns from data frames. Our example data frame has 4 columns, but let’s say we wanted only 2 of them and we wanted to select which ones to keep by using their names, we could write:\n\n```{r}\n# select takes the dataframe as first argument, then the names of the columns you want to keep/exclude\ndf_two_columns <- select(df_data, Animal_ID, Variable)\n\ndf_two_columns\n```\n\n   Animal_ID Variable\n1         11      1.0\n2         12      1.2\n3         21      1.0\n4         22      1.2\n5         11      2.0\n6         12      2.5\n7         21      0.5\n8         22      0.4\n9         11      3.0\n10        12      3.5\n11        21      0.2\n12        22      0.1\n\n\nWe can also specify the columns we don’t want by using a - symbol before it. The following function will give the same result as above but by exluding the unwanted columns.\n\n```{r}\ndf_two_columns <- select(df_data, -Timepoint, -Treatment_Group)\n\ndf_two_columns\n```\n\n   Animal_ID Variable\n1         11      1.0\n2         12      1.2\n3         21      1.0\n4         22      1.2\n5         11      2.0\n6         12      2.5\n7         21      0.5\n8         22      0.4\n9         11      3.0\n10        12      3.5\n11        21      0.2\n12        22      0.1\n\n\nThe select function can also be used with ‘selection helpers’. For example if you want all columns that included a certain bit of text you could use contains(\"text_to_search\"), or if you wanted columns that started with a certain bit of text starts_with(\"text_to_search\"). You can also select columns based on what type of data they contain. Our example data frame has columns of type ‘num’ (number, technically they are a ‘double’), ‘int’ (integer, i.e. a num but not a double) or ‘chr’ (character):\n\n```{r}\nstr(df_data)\n```\n\n'data.frame':   12 obs. of  4 variables:\n $ Animal_ID      : num  11 12 21 22 11 12 21 22 11 12 ...\n $ Timepoint      : int  1 1 1 1 2 2 2 2 3 3 ...\n $ Treatment_Group: chr  \"Treatment A\" \"Treatment A\" \"Treatment B\" \"Treatment B\" ...\n $ Variable       : num  1 1.2 1 1.2 2 2.5 0.5 0.4 3 3.5 ...\n\n\nSo, if we wanted to select the columns with characters we could use the where() helper function:\n\n```{r}\nselect(df_data, where(is.character))\n```\n\n   Treatment_Group\n1      Treatment A\n2      Treatment A\n3      Treatment B\n4      Treatment B\n5      Treatment A\n6      Treatment A\n7      Treatment B\n8      Treatment B\n9      Treatment A\n10     Treatment A\n11     Treatment B\n12     Treatment B\n\n\n\n\n\n\n\n\nNote\n\n\n\nis.character() is a function in itself. By using it inside where() it lets you use it safely with the select function. E.g. you could test if some object or column is a character directly with it: is.character(df_data$Animal_ID) = FALSE is.character(df_data$Treatment_Group) = TRUE\n\n\nThe select function also returns the data frame with the columns in the order you specify. Sometimes you might have 100 columns, and you mutate a new column onto the end, but you want it to appear first. You could use the ‘everything()’ helper as follows:\n\n```{r}\n# selects the column of interst first, then returns 'everything' else\nselect(df_data, Variable, everything())\n```\n\n   Variable Animal_ID Timepoint Treatment_Group\n1       1.0        11         1     Treatment A\n2       1.2        12         1     Treatment A\n3       1.0        21         1     Treatment B\n4       1.2        22         1     Treatment B\n5       2.0        11         2     Treatment A\n6       2.5        12         2     Treatment A\n7       0.5        21         2     Treatment B\n8       0.4        22         2     Treatment B\n9       3.0        11         3     Treatment A\n10      3.5        12         3     Treatment A\n11      0.2        21         3     Treatment B\n12      0.1        22         3     Treatment B\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere’s actually another function called relocate() that makes this even easier:\n\n\nCode\n```{r}\n#| code-fold: true\n#| eval: false\nrelocate(df_data, Variable)\n```"
  },
  {
    "objectID": "data_wrangling.html#using-pipes",
    "href": "data_wrangling.html#using-pipes",
    "title": "3  Data wrangling",
    "section": "3.5 Using pipes",
    "text": "3.5 Using pipes\nAt this point we should introduce one of the most useful aspects of using the tidyverse, pipes.\nPipe refers to: %>% (or |> if using R’s newly inbuilt pipe, see Global Options in RStudio)\nWhen working with data that has been imported there are normally multiple ‘data wrangling’ steps involved, such as selecting columns of interest, adding new columns of calculated values, filtering out rows of interest, etc. Each of these steps can get messy in the code when each step is taking a data frame as input and giving a new data frame as output. So, the %>% is used to keep the code more readable.\nThe %>% takes the output from function and gives it to the first position/argument of the next function, without having to save it as a variable in your environment. It takes this structure: output_from_previous %>% next_function(argument1 = 1, argument2 = 3) is the same as next_function(output_from_previous, argument1 = 1, argument2 = 3) Notice how the ‘output_from_previous’ object is placed into the first position of the next function by the pipe.\nFor the first pipe in a chain of pipes the ‘output_from_previous’ is normally just a starting data frame object itself, which is parsed to the first position of the function: df_data %>% next_function()\nLet’s take the above select function example and re-write it using the pipe:\n\n```{r}\n#Original:\n#df_two_columns <- select(df_data, Animal_ID, Variable)\n\ndf_two_columns <- df_data %>% select(Animal_ID, Variable)\n\ndf_two_columns\n```\n\n   Animal_ID Variable\n1         11      1.0\n2         12      1.2\n3         21      1.0\n4         22      1.2\n5         11      2.0\n6         12      2.5\n7         21      0.5\n8         22      0.4\n9         11      3.0\n10        12      3.5\n11        21      0.2\n12        22      0.1\n\n\nFor this example it makes very little difference to the ‘readability’ of the code. But let’s say we have 3 steps of cleaning we want to do:\n\nSelect 3 columns: Animal_ID, Variable, Treatment_Group\nArrange the columns in order of Animal_ID\nFilter out any rows that have a ‘Variable’ reading of less than 1\n\nWithout pipes we might do this.\nStep 1 - select:\n\n```{r}\ndf_step1 <- select(df_data, Animal_ID, Variable, Treatment_Group)\n\ndf_step1\n```\n\n   Animal_ID Variable Treatment_Group\n1         11      1.0     Treatment A\n2         12      1.2     Treatment A\n3         21      1.0     Treatment B\n4         22      1.2     Treatment B\n5         11      2.0     Treatment A\n6         12      2.5     Treatment A\n7         21      0.5     Treatment B\n8         22      0.4     Treatment B\n9         11      3.0     Treatment A\n10        12      3.5     Treatment A\n11        21      0.2     Treatment B\n12        22      0.1     Treatment B\n\n\nStep 2 - arrange:\n\n```{r}\ndf_step2 <- arrange(df_step1, Animal_ID)\n\ndf_step2\n```\n\n   Animal_ID Variable Treatment_Group\n1         11      1.0     Treatment A\n2         11      2.0     Treatment A\n3         11      3.0     Treatment A\n4         12      1.2     Treatment A\n5         12      2.5     Treatment A\n6         12      3.5     Treatment A\n7         21      1.0     Treatment B\n8         21      0.5     Treatment B\n9         21      0.2     Treatment B\n10        22      1.2     Treatment B\n11        22      0.4     Treatment B\n12        22      0.1     Treatment B\n\n\nStep 3 - filter:\n\n```{r}\n#The ! symbol means NOT and negates a check. Here it is used when you want to exclude rather than keep what you are filtering.\ndf_step3 <- filter(df_step2, !Variable < 1)\n\ndf_step3\n```\n\n  Animal_ID Variable Treatment_Group\n1        11      1.0     Treatment A\n2        11      2.0     Treatment A\n3        11      3.0     Treatment A\n4        12      1.2     Treatment A\n5        12      2.5     Treatment A\n6        12      3.5     Treatment A\n7        21      1.0     Treatment B\n8        22      1.2     Treatment B\n\n\nThis creates a lot of variables in your environment which wastes memory and is difficult to keep track of. Therefore, we can use pipes to do the same:\n\n```{r}\ndf_out <- df_data %>% \n  select(Animal_ID, Variable, Treatment_Group) %>%  \n  arrange(Animal_ID) %>% \n  filter(!Variable < 1) \n\n\ndf_out\n```\n\n  Animal_ID Variable Treatment_Group\n1        11      1.0     Treatment A\n2        11      2.0     Treatment A\n3        11      3.0     Treatment A\n4        12      1.2     Treatment A\n5        12      2.5     Treatment A\n6        12      3.5     Treatment A\n7        21      1.0     Treatment B\n8        22      1.2     Treatment B\n\n\nWhen troubleshooting a problem in a chain of functions, you can split the chain at any point by removing a %>% and returning everything up to that point to help you visualise what the data frame looks like at that point in the chain."
  },
  {
    "objectID": "data_wrangling.html#import-data",
    "href": "data_wrangling.html#import-data",
    "title": "3  Data wrangling",
    "section": "3.6 Import data",
    "text": "3.6 Import data\nNormally we are interested in importing some data we have stored in a spreadsheet, such as what we might have in Excel.\nIf we’ve collected data in an experiment, it’s probably in a nicely formatted Excel format that is terrible for computer to read. Often it is easiest to re-format your tables with 1 row for column headings, and remove all formatting.\nSometimes this is best done by saving a sheet to a plain text format such as .csv or .txt. It also means your data isn’t modified automatically by Excel (such as some gene names being converted to dates e.g. MARCH1, which have now been renamed because of this ).\nPlain text files are one of the most standard ways of saving data for both humans and software to read, and for most data we work with from experiments it is relatively fast. But note, there are much more efficient ways of handling bigger data sets: https://r4ds.hadley.nz/arrow.html\n\n```{r}\n# find the file path to a demo dataset\n\nmy_filepath <- palmerpenguins::path_to_file(\"penguins_raw.csv\")\n\nprint(my_filepath)\n```\n\n[1] \"C:/Users/david/AppData/Local/R/win-library/4.2/palmerpenguins/extdata/penguins_raw.csv\"\n\n\nUse this filepath to import with `data.table::fread()`\n\n```{r}\ndf_in <- read_csv(file = my_filepath)\n```\n\nRows: 344 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): studyName, Species, Region, Island, Stage, Individual ID, Clutch C...\ndbl  (7): Sample Number, Culmen Length (mm), Culmen Depth (mm), Flipper Leng...\ndate (1): Date Egg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n```{r}\n# View(df_in)\n```\n\nCheck the dimensions and structure of your data to make sure it’s imported how you expected:\n\n```{r}\n# just the dimensions\ndim(df_in)\n\n# structure of df\nstr(df_in)\n```\n\n[1] 344  17\nspc_tbl_ [344 × 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ studyName          : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ Sample Number      : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ Species            : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ Region             : chr [1:344] \"Anvers\" \"Anvers\" \"Anvers\" \"Anvers\" ...\n $ Island             : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ Stage              : chr [1:344] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" ...\n $ Individual ID      : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ Clutch Completion  : chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Date Egg           : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ Culmen Length (mm) : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ Culmen Depth (mm)  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ Flipper Length (mm): num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ Body Mass (g)      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ Sex                : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ Delta 15 N (o/oo)  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ Delta 13 C (o/oo)  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ Comments           : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n\n\n\n\nNote\n\n\n\nMy personal preference is to use the fread() function from the data.table package (which is a popular alternative to the tidyverse way of working with data). I’ve found it to be good at guessing what type of data is in each column, for various file formats and is faster than other functions (fread is short for ‘fast read’).\nIt also works with multiple filetypes and guesses what to do based on the file extension of the file.\n\n\nIt is good practice to store your input files for your scripts in a subfolder of your Project directory called ‘Inputs’ or ‘data’ or something similar. That way, you are storing a copy of the original data with your scripts, and you can use relative filepaths:\n\ndf_in <- read_csv(\"./Inputs/my_awesome_data.csv\")\n\n\n3.6.1 Reading in excel files\nIt has become easier to read data directly from excel sheets. It is still worth remembering that data you see formatted in cells in Excel is not always a good representation of what is stored underneath it (e.g. dates as the number of seconds since January 1, 1970). Let the function try and guess the data types correctly, and modify if neccesary. See details: https://r4ds.hadley.nz/spreadsheets.html\nYou can also specify which sheet to import.\n\ndf_in <- read_excel(\"./Inputs/my_awesome_excel_file.xlsx\", sheet = \"Sheet 1\")\n\n\n\n\n\n\n\nTab completion\n\n\n\nWhen writing a file path to import or export a file, you can press the Tab button on your keyboard after you type \"./\", and it will display a list of files and folders. Tab complete is useful for typing long variable or function names too.\n\n\n\n\n3.6.2 Column names\nWhen we looked at the raw data from palmerpenguins we noticed that some of the column names had spaces in them. We can technically get by with this using ticks:\n\ndf_in$`Sample Number`\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the $ is a base R way of accessing the values within a column\n\n\nTo fix these column names we can either:\n\nTell read_csv what names to use:\n\n\n```{r}\nread_csv(my_filepath, \n         col_names = c(\"studyName\", 'sample_number', 'Species'), \n         show_col_types = FALSE # this stops the message about cols printing\n         )\n```\n\n# A tibble: 345 × 17\n   study…¹ sampl…² Species X4    X5    X6    X7    X8    X9    X10   X11   X12  \n   <chr>   <chr>   <chr>   <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n 1 studyN… Sample… Species Regi… Isla… Stage Indi… Clut… Date… Culm… Culm… Flip…\n 2 PAL0708 1       Adelie… Anve… Torg… Adul… N1A1  Yes   2007… 39.1  18.7  181  \n 3 PAL0708 2       Adelie… Anve… Torg… Adul… N1A2  Yes   2007… 39.5  17.4  186  \n 4 PAL0708 3       Adelie… Anve… Torg… Adul… N2A1  Yes   2007… 40.3  18    195  \n 5 PAL0708 4       Adelie… Anve… Torg… Adul… N2A2  Yes   2007… <NA>  <NA>  <NA> \n 6 PAL0708 5       Adelie… Anve… Torg… Adul… N3A1  Yes   2007… 36.7  19.3  193  \n 7 PAL0708 6       Adelie… Anve… Torg… Adul… N3A2  Yes   2007… 39.3  20.6  190  \n 8 PAL0708 7       Adelie… Anve… Torg… Adul… N4A1  No    2007… 38.9  17.8  181  \n 9 PAL0708 8       Adelie… Anve… Torg… Adul… N4A2  No    2007… 39.2  19.6  195  \n10 PAL0708 9       Adelie… Anve… Torg… Adul… N5A1  Yes   2007… 34.1  18.1  193  \n# … with 335 more rows, 5 more variables: X13 <chr>, X14 <chr>, X15 <chr>,\n#   X16 <chr>, X17 <chr>, and abbreviated variable names ¹​studyName,\n#   ²​sample_number\n\n\nAs you can see, we would have to write out all 17 column names otherwise it gets a generic name like X4\n\nTherefore, we could just rename some by hand:\n\n\n```{r}\n# view current column names\ncolnames(df_in)\n\ndf_in <- \n  df_in %>% \n  rename(\n    # new_name = old_name\n    sample_number = `Sample Number`,\n    individual_ID = `Individual ID` # etc.\n  )\n\n# check new column names\n# colnames(df_in)\n```\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n\nWe can also use janitor::clean_names() to fix them automatically:\n\n\n```{r}\n# You may need to run: install.packages(\"janitor\")\ndf_in <- \n  df_in %>% \n  janitor::clean_names()\n\ncolnames(df_in)\n```\n\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n[13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n[16] \"delta_13_c_o_oo\"   \"comments\""
  },
  {
    "objectID": "data_wrangling.html#task",
    "href": "data_wrangling.html#task",
    "title": "3  Data wrangling",
    "section": "3.7 Task:",
    "text": "3.7 Task:\n\nImport your own data into R\nCheck the structure of the data frame (data types in each column)\nRename some columns so they are all easy to work with"
  },
  {
    "objectID": "data_wrangling.html#other-useful-basic-tools",
    "href": "data_wrangling.html#other-useful-basic-tools",
    "title": "3  Data wrangling",
    "section": "3.8 Other useful basic tools",
    "text": "3.8 Other useful basic tools\n\n3.8.1 mutate\nThe mutate() function is another dplyr verb you’ll use a lot. It adds columns to your current data frame. For this we will use our own simple data frame that we created earlier.\nWe can add a single values to all rows of a data frame:\n\n```{r}\ndf_data %>% \n  mutate(new_col = 1,\n         another_col = \"hello\")\n```\n\n   Animal_ID Timepoint Treatment_Group Variable new_col another_col\n1         11         1     Treatment A      1.0       1       hello\n2         12         1     Treatment A      1.2       1       hello\n3         21         1     Treatment B      1.0       1       hello\n4         22         1     Treatment B      1.2       1       hello\n5         11         2     Treatment A      2.0       1       hello\n6         12         2     Treatment A      2.5       1       hello\n7         21         2     Treatment B      0.5       1       hello\n8         22         2     Treatment B      0.4       1       hello\n9         11         3     Treatment A      3.0       1       hello\n10        12         3     Treatment A      3.5       1       hello\n11        21         3     Treatment B      0.2       1       hello\n12        22         3     Treatment B      0.1       1       hello\n\n\nIt’s more likely that will want to take a column we already have, do something to it and store it in a new column:\n\n```{r}\ndf_data %>% \n  mutate(\n    Variable_doubled = Variable * 2\n  )\n```\n\n   Animal_ID Timepoint Treatment_Group Variable Variable_doubled\n1         11         1     Treatment A      1.0              2.0\n2         12         1     Treatment A      1.2              2.4\n3         21         1     Treatment B      1.0              2.0\n4         22         1     Treatment B      1.2              2.4\n5         11         2     Treatment A      2.0              4.0\n6         12         2     Treatment A      2.5              5.0\n7         21         2     Treatment B      0.5              1.0\n8         22         2     Treatment B      0.4              0.8\n9         11         3     Treatment A      3.0              6.0\n10        12         3     Treatment A      3.5              7.0\n11        21         3     Treatment B      0.2              0.4\n12        22         3     Treatment B      0.1              0.2\n\n\nThis is similar to how we multiplied every element of a vector by 1 number earlier. We can also use functions, and also refer to the column we just calculated in the next row:\n\n```{r}\ndf_data %>% \n  mutate(\n    variable_mean = mean(Variable),\n    variable_minus_mean = Variable - variable_mean\n  )\n\n# In reality we would just do: \n# mutate(variable_minus_mean = Variable - mean(variable_mean))\n```\n\n   Animal_ID Timepoint Treatment_Group Variable variable_mean\n1         11         1     Treatment A      1.0      1.383333\n2         12         1     Treatment A      1.2      1.383333\n3         21         1     Treatment B      1.0      1.383333\n4         22         1     Treatment B      1.2      1.383333\n5         11         2     Treatment A      2.0      1.383333\n6         12         2     Treatment A      2.5      1.383333\n7         21         2     Treatment B      0.5      1.383333\n8         22         2     Treatment B      0.4      1.383333\n9         11         3     Treatment A      3.0      1.383333\n10        12         3     Treatment A      3.5      1.383333\n11        21         3     Treatment B      0.2      1.383333\n12        22         3     Treatment B      0.1      1.383333\n   variable_minus_mean\n1           -0.3833333\n2           -0.1833333\n3           -0.3833333\n4           -0.1833333\n5            0.6166667\n6            1.1166667\n7           -0.8833333\n8           -0.9833333\n9            1.6166667\n10           2.1166667\n11          -1.1833333\n12          -1.2833333\n\n\nIt’s also useful to replace the column, especially if we transform its type:\n\n```{r}\ndf_data %>% \n  mutate(\n    Variable = as.integer(Variable),\n    Treatment_Group = as.factor(Treatment_Group)\n  )\n```\n\n   Animal_ID Timepoint Treatment_Group Variable\n1         11         1     Treatment A        1\n2         12         1     Treatment A        1\n3         21         1     Treatment B        1\n4         22         1     Treatment B        1\n5         11         2     Treatment A        2\n6         12         2     Treatment A        2\n7         21         2     Treatment B        0\n8         22         2     Treatment B        0\n9         11         3     Treatment A        3\n10        12         3     Treatment A        3\n11        21         3     Treatment B        0\n12        22         3     Treatment B        0\n\n\nIt’s also works well with tidyselect functions, like we did using select(). But this time we need the across() function, which is a little more advanced but super useful. See https://r4ds.hadley.nz/iteration.html\nHere we will use the penguins dataset again.\nIf we wanted to divide all numeric columns by 100 and then round to 1 digits we could do:\n\n```{r}\npenguins %>% \n  mutate(\n    across(where(is.numeric), ~ .x / 100),\n    across(where(is.numeric), ~round(.x, digits = 1))\n    )\n```\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_…¹ body_…² sex    year\n   <fct>   <fct>              <dbl>         <dbl>      <dbl>   <dbl> <fct> <dbl>\n 1 Adelie  Torgersen            0.4           0.2        1.8    37.5 male   20.1\n 2 Adelie  Torgersen            0.4           0.2        1.9    38   fema…  20.1\n 3 Adelie  Torgersen            0.4           0.2        2      32.5 fema…  20.1\n 4 Adelie  Torgersen           NA            NA         NA      NA   <NA>   20.1\n 5 Adelie  Torgersen            0.4           0.2        1.9    34.5 fema…  20.1\n 6 Adelie  Torgersen            0.4           0.2        1.9    36.5 male   20.1\n 7 Adelie  Torgersen            0.4           0.2        1.8    36.2 fema…  20.1\n 8 Adelie  Torgersen            0.4           0.2        2      46.8 male   20.1\n 9 Adelie  Torgersen            0.3           0.2        1.9    34.8 <NA>   20.1\n10 Adelie  Torgersen            0.4           0.2        1.9    42.5 <NA>   20.1\n# … with 334 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#   ²​body_mass_g\n\n\nThis functionality is even more useful with summarise() which we will touch on in the next chapter.\n\n\n3.8.2 Filter data\nAnother common task we have is to filter out rows of data based on some criteria we have. Let’s say we only wanted the data from Animal 22:\n\n```{r}\ndf_data %>% \n  filter(Animal_ID == 22)\n```\n\n  Animal_ID Timepoint Treatment_Group Variable\n1        22         1     Treatment B      1.2\n2        22         2     Treatment B      0.4\n3        22         3     Treatment B      0.1\n\n\nWe can negate this to show everything other than Animal 22:\n\n```{r}\ndf_data %>% \n  filter(!Animal_ID == 22) \n# filter(Animal_ID != 22) also works\n```\n\n  Animal_ID Timepoint Treatment_Group Variable\n1        11         1     Treatment A      1.0\n2        12         1     Treatment A      1.2\n3        21         1     Treatment B      1.0\n4        11         2     Treatment A      2.0\n5        12         2     Treatment A      2.5\n6        21         2     Treatment B      0.5\n7        11         3     Treatment A      3.0\n8        12         3     Treatment A      3.5\n9        21         3     Treatment B      0.2\n\n\nWe can specify multiple conditions:\n\n```{r}\n# AND operator is &\ndf_data %>% \n  filter(Animal_ID != 22 & Timepoint == 2)\n```\n\n  Animal_ID Timepoint Treatment_Group Variable\n1        11         2     Treatment A      2.0\n2        12         2     Treatment A      2.5\n3        21         2     Treatment B      0.5\n\n\n\n```{r}\n# OR operator is |\ndf_data %>% \n  filter(Animal_ID == 22 | Timepoint == 2)\n```\n\n  Animal_ID Timepoint Treatment_Group Variable\n1        22         1     Treatment B      1.2\n2        11         2     Treatment A      2.0\n3        12         2     Treatment A      2.5\n4        21         2     Treatment B      0.5\n5        22         2     Treatment B      0.4\n6        22         3     Treatment B      0.1\n\n\nWe can also use %in% to match multiple values\n\n```{r}\ndf_data %>% \n  filter(Timepoint %in% c(1,3))\n```\n\n  Animal_ID Timepoint Treatment_Group Variable\n1        11         1     Treatment A      1.0\n2        12         1     Treatment A      1.2\n3        21         1     Treatment B      1.0\n4        22         1     Treatment B      1.2\n5        11         3     Treatment A      3.0\n6        12         3     Treatment A      3.5\n7        21         3     Treatment B      0.2\n8        22         3     Treatment B      0.1\n\n\n\n\n3.8.3 Handling NA values\nNormally it is best to leave rows in place that contain NA values because no functions in the tidyverse will drop NA values without notifying you.\nIf you need to remove rows with NA values you can use tidyr::drop_na(). With this you can tell it which columns to inspect for missing values.\nBefore you do this, check out this explanation of missing values here: https://r4ds.hadley.nz/missing-values.html\n\n\n\n\n\n\nNote\n\n\n\nWe haven’t talked about dates or times here. It takes a little bit of time to learn, but keep in mind that ggplot works very nicely with dates and times, so take the time to format your timeseries data correctly: https://r4ds.hadley.nz/datetimes.html"
  },
  {
    "objectID": "data_wrangling.html#tasks",
    "href": "data_wrangling.html#tasks",
    "title": "3  Data wrangling",
    "section": "3.9 Tasks:",
    "text": "3.9 Tasks:\n\nAdd a column to your own data so that each row contains the string “cows” using mutate()\nRemove column using select()\nAdd a column to your own data with a calculation using an existing column\nCreate a subset of data using filter()"
  },
  {
    "objectID": "summarising_data.html#split-apply-combine-concept",
    "href": "summarising_data.html#split-apply-combine-concept",
    "title": "4  Summarising data",
    "section": "4.1 Split-apply-combine concept",
    "text": "4.1 Split-apply-combine concept\nAs we will see, one of the most useful tools is the group_by() function. This works on the ‘split-apply-combine’ principal where you split the data up into smaller tables, do something to those smaller tables, then put all the data back together again.\nLet’s say we wanted to know the sum of the Variable column, we could do:\n\n```{r}\nsum(df_data$Variable)\n```\n\n[1] 16.6\n\n\nAs we learnt in the previous chapter, we could store this in a new column using mutate():\n\n```{r}\ndf_data %>% mutate(sum_total = sum(Variable))\n```\n\n   Animal_ID Timepoint Treatment_Group Variable sum_total\n1         11         1     Treatment A      1.0      16.6\n2         12         1     Treatment A      1.2      16.6\n3         21         1     Treatment B      1.0      16.6\n4         22         1     Treatment B      1.2      16.6\n5         11         2     Treatment A      2.0      16.6\n6         12         2     Treatment A      2.5      16.6\n7         21         2     Treatment B      0.5      16.6\n8         22         2     Treatment B      0.4      16.6\n9         11         3     Treatment A      3.0      16.6\n10        12         3     Treatment A      3.5      16.6\n11        21         3     Treatment B      0.2      16.6\n12        22         3     Treatment B      0.1      16.6\n\n\nBut let’s say we wanted to know the sum of the variable column for each Treatment (not total). If we ‘group_by’ Treatment_Group first, then behind the scenes the sum function will first be given a subset of the dataframe containing only the Treatment A data, then it will be given all of the Treatment B data. To do it manually we would have to do do:\n\n```{r}\ndf_treatmentA <- df_data %>% filter(Treatment_Group == 'Treatment A')\n\nsum(df_treatmentA$Variable)\n```\n\n[1] 13.2\n\n\nThen we would then have to repeat this for all of the treatments, which is not ideal. So, one might consider using a function to help, like:\n\n```{r}\n# 1. get all unique names in Treatment_Group\ntreatments <- unique(df_data$Treatment_Group)\n\ntreatments\n```\n\n[1] \"Treatment A\" \"Treatment B\"\n\n\n\n```{r}\n#2. Write a function\nf_groupsums <- function(x){\n  df_temp <- df_data %>% filter(Treatment_Group == x)\n  \n  return(sum(df_temp$Variable))\n}\n\n#3. use apply to iterate through the treatments \nlapply(treatments, f_groupsums)\n```\n\n[[1]]\n[1] 13.2\n\n[[2]]\n[1] 3.4\n\n\nThis takes a lot of code,is probably a little scary if you’re not used to making functions, and returns a list of numbers that you then need to process further to get the treatment names for them."
  },
  {
    "objectID": "summarising_data.html#the-easy-way",
    "href": "summarising_data.html#the-easy-way",
    "title": "4  Summarising data",
    "section": "4.2 The easy way",
    "text": "4.2 The easy way\nInstead, we use group_by with the summarise function instead. The summarise function is like mutate, except you use functions inside it that summarise the data, returning single values per group:\n\n```{r}\ndf_data %>% \n  group_by(Treatment_Group) %>% \n  summarise(sum_groups = sum(Variable))\n```\n\n# A tibble: 2 × 2\n  Treatment_Group sum_groups\n  <chr>                <dbl>\n1 Treatment A           13.2\n2 Treatment B            3.4\n\n\nThis gives the same numbers, only in a nice data frame.\nIt’s also possible to group by multiple columns:\n\n```{r}\ndf_data %>% \n  group_by(Treatment_Group, Timepoint) %>% \n  summarise(sum_groups = sum(Variable))\n```\n\n`summarise()` has grouped output by 'Treatment_Group'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   Treatment_Group [2]\n  Treatment_Group Timepoint sum_groups\n  <chr>               <int>      <dbl>\n1 Treatment A             1        2.2\n2 Treatment A             2        4.5\n3 Treatment A             3        6.5\n4 Treatment B             1        2.2\n5 Treatment B             2        0.9\n6 Treatment B             3        0.3\n\n\nYou could actually still use mutate if you wanted to store this in a column of the original data frame (useful for some calculations, such as % within a group)\n\n```{r}\ndf_data %>% \n  group_by(Treatment_Group) %>% \n  mutate(sum_groups = sum(Variable),\n         perc_of_group_sum = Variable/sum_groups*100) %>% \n    arrange(Treatment_Group) #just to make it nicer to read\n```\n\n# A tibble: 12 × 6\n# Groups:   Treatment_Group [2]\n   Animal_ID Timepoint Treatment_Group Variable sum_groups perc_of_group_sum\n       <dbl>     <int> <chr>              <dbl>      <dbl>             <dbl>\n 1        11         1 Treatment A          1         13.2              7.58\n 2        12         1 Treatment A          1.2       13.2              9.09\n 3        11         2 Treatment A          2         13.2             15.2 \n 4        12         2 Treatment A          2.5       13.2             18.9 \n 5        11         3 Treatment A          3         13.2             22.7 \n 6        12         3 Treatment A          3.5       13.2             26.5 \n 7        21         1 Treatment B          1          3.4             29.4 \n 8        22         1 Treatment B          1.2        3.4             35.3 \n 9        21         2 Treatment B          0.5        3.4             14.7 \n10        22         2 Treatment B          0.4        3.4             11.8 \n11        21         3 Treatment B          0.2        3.4              5.88\n12        22         3 Treatment B          0.1        3.4              2.94\n\n\nThis same principal applies to all base functions (e.g. mean, max, min, etc) or you can write custom functions and use them with mutate and summarise:\n\n```{r}\ndf_data %>% \n  group_by(Treatment_Group) %>% \n  summarise(mean_variable = mean(Variable, na.rm=TRUE)) #use na.rm=TRUE if you want the mean function to ignore NA values\n```\n\n# A tibble: 2 × 2\n  Treatment_Group mean_variable\n  <chr>                   <dbl>\n1 Treatment A             2.2  \n2 Treatment B             0.567"
  },
  {
    "objectID": "summarising_data.html#summarising-multiple-columns",
    "href": "summarising_data.html#summarising-multiple-columns",
    "title": "4  Summarising data",
    "section": "4.3 Summarising multiple columns",
    "text": "4.3 Summarising multiple columns\nAs we mentioned previously, we can use tidyselect with across() to efficiently iterate through our columns.\nLet’s say we want to find the mean and sd of all columns that contain numbers. We could write it out in long form:\n\n```{r}\npenguins %>% \n  group_by(species) %>% \n  summarise(bill_length_mean = mean(bill_length_mm, na.rm = TRUE),\n            bill_length_sd = sd(bill_length_mm, na.rm = TRUE),\n            bill_depth_mean = mean(bill_depth_mm, na.rm = TRUE),\n            bill_depth_sd = sd(bill_depth_mm, na.rm = TRUE)\n            #etc....\n            )\n```\n\n# A tibble: 3 × 5\n  species   bill_length_mean bill_length_sd bill_depth_mean bill_depth_sd\n  <fct>                <dbl>          <dbl>           <dbl>         <dbl>\n1 Adelie                38.8           2.66            18.3         1.22 \n2 Chinstrap             48.8           3.34            18.4         1.14 \n3 Gentoo                47.5           3.08            15.0         0.981\n\n\nOr, we can use across():\n\n```{r}\npenguins %>% \n  group_by(species) %>% \n  summarise(\n    across(.cols = where(is.numeric),\n           .fns = list(mean = ~mean(.x, na.rm = TRUE),\n                       sd = ~sd(.x, na.rm=TRUE)),\n           .names = '{.col}_{.fn}') #see ?across for details on how this works\n  )\n```\n\n# A tibble: 3 × 11\n  species   bill_lengt…¹ bill_…² bill_…³ bill_…⁴ flipp…⁵ flipp…⁶ body_…⁷ body_…⁸\n  <fct>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Adelie            38.8    2.66    18.3   1.22     190.    6.54   3701.    459.\n2 Chinstrap         48.8    3.34    18.4   1.14     196.    7.13   3733.    384.\n3 Gentoo            47.5    3.08    15.0   0.981    217.    6.48   5076.    504.\n# … with 2 more variables: year_mean <dbl>, year_sd <dbl>, and abbreviated\n#   variable names ¹​bill_length_mm_mean, ²​bill_length_mm_sd,\n#   ³​bill_depth_mm_mean, ⁴​bill_depth_mm_sd, ⁵​flipper_length_mm_mean,\n#   ⁶​flipper_length_mm_sd, ⁷​body_mass_g_mean, ⁸​body_mass_g_sd"
  },
  {
    "objectID": "summarising_data.html#task",
    "href": "summarising_data.html#task",
    "title": "4  Summarising data",
    "section": "4.4 Task:",
    "text": "4.4 Task:\n\nChoose 1 variable from you data and calculate the mean and sd for each treatment (or another relevant group)\nMutate 2 new columns to your summary table called ymin and ymax, containing the values calculated from mean - SD and mean + SD, respectively.\nAdvanced: re-calculate your summary table but also include the number of samples per group."
  },
  {
    "objectID": "first_plot.html#grammar-of-graphics-ggplot2",
    "href": "first_plot.html#grammar-of-graphics-ggplot2",
    "title": "5  Making your first plot",
    "section": "5.1 Grammar of Graphics & ggplot2",
    "text": "5.1 Grammar of Graphics & ggplot2\nThe ggplot2 package was written by Hadley Wickham and is based on the book ‘The Grammar of Graphics’ by Leland Wilkinson (2005), with some modifications. See https://ggplot2-book.org/ or http://vita.had.co.nz/papers/layered-grammar.pdf for more details on the theory behind the grammar in ggplot2.\nThe grammar is a coherent way of describing your plot using element that apply to any plot you want to make. These elements are built up into a plot using layers. Together, a graphic is produced that maps the data to aesthetic attributes of geometric objects.\n\naes(): aesthetic attributes - Colour, shape, size, linetype, linewidth, etc. The data can be mapped to these. E.g. each treatment could be a different colour on your plot by mapping the column containg the treatments to the colour aesthetic.\ngeom_: geometric object - This is what you see: “visual marks that represent data points”. The points, lines, polygons, etc.They also usually define what ‘type’ of plot it is, and is kind of similar to the types of plots you see in Excel.\n\nThe finer details of mapping is described with scales, coordindate systems, facets and themes. See links above for theory but they will be covered as we go in the following examples.\nBuilding the layers:\n\nThe function call. Calling ggplot() initialises a ggplot object.\n\n\n```{r}\nggplot()\n```\n\n\n\n\n\nAdding data and aesthetics. With the x and y axis mapped to some values, the scales can be drawn.\n\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, y =  bill_length_mm))\n```\n\n\n\n\n\nAdd geoms (geometric objects).\n\nE.g. this adds geom_point() which is similar to a scatter plot in Excel. Notice we are using a + symbol to add layers of information to the ggplot, not a pipe.\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, y =  bill_length_mm))+\n  geom_point()\n```\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nWe can also layer on additional geoms. Let’s try adding a regression line suing geom_smooth()\n\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, y =  bill_length_mm))+\n  geom_point()+\n  geom_smooth(method = 'lm') #lm = linear model\n```\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlots displayed below code chunks\n\n\n\nWhen we generate some plots, they will be displayed below the code chunks. Various controls are available to changing the size of the figures and how they look. For example, figure width can be set to 8 or 10 for larger plots by adding {r fig.width = 10} at the start of code chunk.\nTo view plots in the ‘Plots’ window inside RStudio, copy and paste the code that generates the plot into the ‘Console’ directly (keyboard shortcut Ctrl + 2) and run it. This will let you Zoom and Export directly if needed. We will also cover saving plots at end of this chapter.\n\n\n\nWe can keep layering (+), modifying scales, faceting, adding themes and other customisations. We know there are more columns of data with important information, so let’s map the column sex to the colour aes\n\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm,\n                     colour = sex))+\n  geom_point()\n```\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIf we were to add our regression line again now, we would see that it is split by the same groups as our colour aes:\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm,\n                     colour = sex))+\n  geom_point()+\n  geom_smooth(method = 'lm')\n```\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nRemember you can see what aesthethics are relevant (and required) for each geom by looking at the help page for the geom you’re working with\n\n\nMaybe we should also map the island information to an aes. We can still easily add different shapes to the points:\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm,\n                     colour = sex,\n                     shape = island))+\n  geom_point()+\n  geom_smooth(method = 'lm')\n```\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNow would be a good time to mention that so far we have specified aes() at the ‘whole plot’ level, but we can actually map values to 1 particular geom_. In this case, we might still prefer to have 1 regression line for the whole data set. So, we know that x = and y = will stay the same for all layers this time, but we can be more specific about our colour = and shape =\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm))+\n  geom_point(aes(colour = sex, shape = island))+\n  geom_smooth(method = 'lm')\n```\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIt’s starting to get a little crowded. Let’s drop the regression line and try mapping the species column to the point size aes.\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm\n                     ))+\n  geom_point(aes(size = species,\n                 colour = sex,\n                 shape = island))\n```\n\nWarning: Using size for a discrete variable is not advised.\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIt’s getting messy! but it does seem like the points are clustering by species. It might be easier if we split the plot into facets (subplots) for each species."
  },
  {
    "objectID": "first_plot.html#facets",
    "href": "first_plot.html#facets",
    "title": "5  Making your first plot",
    "section": "5.2 Facets",
    "text": "5.2 Facets\nThere are 2 key functions we can use to split our plots up easily:\n\nfacet_wrap(): wrap facets into a rectangle\nfacet_grid(): facets into either columns, rows or both\n\nSee the cheat sheet for a visual on the differences.\nOften if we have 1 variable we are interested in faceting by, and we are just exploring the data, we can quickly lay out the facets using facet_wrap(). Just like aes() helps us quote column names for the mapping = argument, vars() helps us tell the facet functions which columns to use.\n\n```{r}\nggplot(data = penguins, \n       mapping = aes(x = flipper_length_mm, \n                     y =  bill_length_mm\n                     ))+\n  geom_point(aes(colour = sex,\n                 shape = island))+\n  facet_wrap(facets = vars(species))\n```\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThen we might decide to drop the island information, and tidy up the plot with a few tweaks. Don’t mind the code here yet… but we’re starting to get a little fancy and move towards plots for communication/explanation rather than our rough exploratory plots.\nWe can also assign the ggplot to an object name (which puts it in our environment) and then call it again with additional + layers. I’ll assign our fancier graph to the object name p.\n\n\nCode\n```{r}\n#| code-fold: true\np <- \n  penguins %>% \n  drop_na(bill_length_mm, bill_depth_mm, sex) %>% \n  ggplot(aes(x = flipper_length_mm  , y =  bill_length_mm, colour = sex))+\n  geom_point()+\n  scale_color_manual(values = c(\"darkorange\",\"cyan4\"), na.translate = FALSE)+\n  theme_bw()+\n  theme(panel.grid = element_blank())+\n  xlab(\"Flipper Length (mm)\")+\n  ylab(\"Bill Length (mm)\")\n\np +\n  facet_wrap(vars(species))\n```\n\n\n\n\n\nIf we also wanted to facet by sex, we could use facet_grid():\n\n```{r}\np + \n  facet_grid(rows = vars(sex),\n             cols = vars(species))\n```\n\n\n\n\nSometimes we also want to control how the axis are displayed. Normally they are all \"fixed\" so that the axis scales stay the same for all x and all y axis. But we can free them up:\n\n```{r}\n(p <- p + \n  facet_grid(rows = vars(sex),\n             cols = vars(species),\n             scales = \"free\")\n)\n```\n\n\n\n\nIt’s also possible to use ‘free_x’ and ‘free_y’ to control just one."
  },
  {
    "objectID": "first_plot.html#saving-your-plot",
    "href": "first_plot.html#saving-your-plot",
    "title": "5  Making your first plot",
    "section": "5.3 Saving your plot",
    "text": "5.3 Saving your plot\nThe easiest way to save your plot is to use the ggsave() function.\nIt will always save the last plot you made, unless you tell it explicitly which plot to save. It also has a lot of file formats and settings to meet publisher requirements (e.g. TIFF file with a certain DPI).\n\n```{r}\nggsave(filename = \"./Outputs/example_plot.png\",\n       plot = p, \n       width = 8, \n       height = 6,\n       units = \"in\", #inch = default\n       dpi = 450\n       #scale =,\n      )\n```"
  },
  {
    "objectID": "custom.html#labels-and-legends",
    "href": "custom.html#labels-and-legends",
    "title": "6  Customising Plots",
    "section": "6.1 Labels and Legends",
    "text": "6.1 Labels and Legends\nModifying the axis labels and legend title is often a good place to start.\n\n```{r}\n( p_CONC_6_SLN <- \n  p_CONC_6_SLN +\n  xlab(\"Milking Number\")+ # x axis label\n  ylab(\"6′-Sialyllactose (6′SLN) concentration (μg/mL)\") ) #y axis label\n```\n\n\n\n\nNow, we might want to remove the heading for the legend and put the legend at the top:\n\n```{r}\n# rename legend to nothing (\"\")\n# the legend represents an aesthethic, so it's actually this label we are changing.\n(p_CONC_6_SLN <-\n   p_CONC_6_SLN+\n   labs(colour = \"\")+\n   # change position of legend\n   theme(legend.position=\"top\")\n)\n```"
  },
  {
    "objectID": "custom.html#themes",
    "href": "custom.html#themes",
    "title": "6  Customising Plots",
    "section": "6.2 Themes",
    "text": "6.2 Themes\nAbove we introduced the theme() function. There are actually a bunch of built-in themes which is often a good starting point. See: https://ggplot2.tidyverse.org/reference/ggtheme.html\nLet’s add the classic theme. This will override our previous theme() to move legend, so we have added again here, after the built in theme is used.\n\n```{r}\n(p_CONC_6_SLN <-\n   p_CONC_6_SLN+\n   theme_classic()+\n   theme(legend.position=\"top\"))\n```\n\n\n\n\nThis theme() function is where you can customise a lot! To see all of the options, look at the theme help page.\nFor a detailed description of themes, see: https://ggplot2-book.org/polishing.html#modifying-theme-components"
  },
  {
    "objectID": "custom.html#modifying-scales",
    "href": "custom.html#modifying-scales",
    "title": "6  Customising Plots",
    "section": "6.3 Modifying Scales",
    "text": "6.3 Modifying Scales\nOne noticeable problem is that our x axis scale doesn’t show all of the milking numbers like we wanted.\nTo do this we can modify the scale. See details about modifying scales:\n\nhttps://ggplot2-book.org/scales.html\nhttps://scales.r-lib.org/\nhttps://r4ds.hadley.nz/communication.html#scales\n\nIf we quickly wanted to increase the number of ‘breaks’ (the lines we see), then we could increase the n.breaks to a high number. Otherwise we can be more specific.\n\n```{r}\n(p_CONC_6_SLN <- \n   p_CONC_6_SLN+\n   scale_x_continuous(breaks = seq(from = 0, \n                                   to = max(six_SLN_conc_to_plot$Milking), \n                                   by = 1)\n                      ) # we used the seq function to make our numbers.\n   )\n```\n\n\n\n\nWe can also edit the scales if we want to modify the colours used. Previously we were modifying a continuous scale because the x axis is numbers. This time, the colour scale is discrete, but if we want to control the colours manually we can use:\n\n```{r}\np_CONC_6_SLN +\n  scale_colour_manual( values = c(\"red\", \"green\"))\n```\n\n\n\n\nThis wouldn’t be too handy if someone who was colourblind saw this. There’s packages dedicated to colour blind friendly plots, such as viridis. Also check out the ColorBrewer: https://ggplot2.tidyverse.org/reference/scale_brewer.html\n\n```{r}\n(p_CONC_6_SLN <-\n  p_CONC_6_SLN +\n  scale_colour_viridis_d(begin = 0.2, end = 0.8) #_d = discrete\n )\n```"
  },
  {
    "objectID": "custom.html#zooming",
    "href": "custom.html#zooming",
    "title": "6  Customising Plots",
    "section": "6.4 Zooming",
    "text": "6.4 Zooming\nLet’s say we wanted to focus on one part of this plot. There are 2 ways we could attempt to do this.\nIf we modified our scales using ylim() or xlim(), the data is actually removed and this can influence other aspects of your plot.\nNormally we just want to ‘zoom in’. To do this, we use coord_cartesian()\n\n```{r}\np_CONC_6_SLN +\n  coord_cartesian(xlim = c(0, 5), ylim = c(0, 20))\n```"
  },
  {
    "objectID": "custom.html#extensions",
    "href": "custom.html#extensions",
    "title": "6  Customising Plots",
    "section": "6.5 Extensions",
    "text": "6.5 Extensions\nThere’s a lot of possible extensions to ggplot that are collated here: https://exts.ggplot2.tidyverse.org/gallery/\n\n6.5.1 Patchwork - joining plots together\nIn our case, we would need to join 2 plots together. We can use the patchwork package for this: https://patchwork.data-imaginist.com/\nLet’s call our plot p_left, and let’s return to our penguins to get our right hand side plot:\n\n```{r}\np_left <- p_CONC_6_SLN \n\np_right <- \n  penguins %>% \n  drop_na(bill_length_mm, bill_depth_mm, sex) %>% \n  ggplot(aes(x = flipper_length_mm  , y =  bill_length_mm, colour = sex))+\n  geom_point()+\n  scale_color_manual(values = c(\"darkorange\",\"cyan4\"), na.translate = FALSE)+\n  theme_bw()+\n  theme(panel.grid = element_blank())+\n  xlab(\"Flipper Length (mm)\")+\n  ylab(\"Bill Length (mm)\")\n```\n\nTo use the patchwork we simply load the package, and ‘add’ them together:\n\n```{r}\nlibrary(patchwork)\np_left + p_right\n```\n\n\n\n\nThere’s more complex ways to join plots together too, so check out the help page for it.\n\n```{r}\n(p_left + p_right) / p_right\n```"
  },
  {
    "objectID": "custom.html#adding-regressions-with-labels",
    "href": "custom.html#adding-regressions-with-labels",
    "title": "6  Customising Plots",
    "section": "6.6 Adding regressions with labels",
    "text": "6.6 Adding regressions with labels\nTo revisit automatic regression lines, sometimes we want to display some summary stats as well. The ggpubr package has a bunch of useful additions to ggplot, including this one.\n\n```{r}\np_right +\n  geom_smooth(method = 'lm', se = FALSE)+\n  ggpubr::stat_regline_equation(aes(label =  paste(after_stat(eq.label), \n                                                   after_stat(adj.rr.label), \n                                                   after_stat(BIC.label),\n                                                   sep = \"~~~~\")))\n```\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "custom.html#adding-p-values",
    "href": "custom.html#adding-p-values",
    "title": "6  Customising Plots",
    "section": "6.7 Adding p-values",
    "text": "6.7 Adding p-values\nThe ggpubr package is also great for adding p-values to plots. It can get a little tricky when the p-values are calculated elsewhere (e.g. SAS), but the documentation explains everything.\nLet’s pretend we have a couple of P values calculated from outside of R. We can recreate some dummy values here:\n\n```{r}\n# these column names are important. It needs to have group1 and group2, and the p.adj is the name of the label we tell it later.\nstats <- tibble::tribble(\n  ~group1, ~group2,   ~p.adj,\n     1,       2,       0.043,\n     1,       3,       0.001,\n     2,       3,       0.002\n  )\nstats\n```\n\n# A tibble: 3 × 3\n  group1 group2 p.adj\n   <dbl>  <dbl> <dbl>\n1      1      2 0.043\n2      1      3 0.001\n3      2      3 0.002\n\n\nThen, we can add them manually to our plot:\n\n```{r}\np_CONC_6_SLN+\n  ggpubr::stat_pvalue_manual(\n    stats, \n    y.position = 300, step.increase = 0.1,\n    label = \"p.adj\"\n    )\n```\n\n\n\n\nOf course, this doesn’t make a lot of sense for this graph. But you can see how it would be useful for pairwise comparisons."
  },
  {
    "objectID": "custom.html#manual-annotations",
    "href": "custom.html#manual-annotations",
    "title": "6  Customising Plots",
    "section": "6.8 Manual annotations",
    "text": "6.8 Manual annotations\nIf you just wanted to add some stars, like in the original Fig 3 of the paper, we could also annotate the graph manually.\n\n```{r}\n# add annotation column to original data and copy to use here\n\nquick_annot_data <- \nsix_SLN_conc_to_plot %>% \n  ungroup() %>% \n  select(Milking) %>% \n  mutate(annot = case_when(Milking %in% c(1,2) ~ \"*\", TRUE ~ \"\"))\n\np_CONC_6_SLN +\n  geom_text(aes(x = Milking, \n                y = 300, \n                label = annot), \n            data = quick_annot_data, \n            inherit.aes = FALSE )\n```\n\n\n\n\nYou could also add lines, or other text using a similar approach:\n\n```{r}\n## add horizontal line\np_CONC_6_SLN +\n  geom_hline(aes(yintercept = 200), colour = 'red')\n```\n\n\n\n\nOr map some text:\n\n```{r}\np_CONC_6_SLN +\n  geom_text(aes(label = as.character(Milking), y = 200), colour = 'brown')\n```"
  },
  {
    "objectID": "advanced_plots.html#automation-with-functions",
    "href": "advanced_plots.html#automation-with-functions",
    "title": "7  Intro to Advanced Plotting",
    "section": "7.1 Automation with functions",
    "text": "7.1 Automation with functions\nOne of the most useful benefits of using R is that you start to write your own functions to automate tasks.\nLet’s say I had a few hundred lactation curves I wanted to plot individually. I couldn’t facet them all, so I would need to plot them 1 at a time. But if I ever need to repeat something more than 3 times, it deserves to be in a function.\nLet’s revisit the same data from Fischer-Tlustos (2020): https://doi.org/10.3168/jds.2019-17357\nThis time, we will plot each individual animal on own graph. First, let’s plot the raw data in a way that we might want to focus on some individual animals.\n\n```{r}\np_raw <- \n  six_SLN %>% \n  ggplot(aes(x = Milking, y = six_SLN_conc, colour = Parity))+\n  geom_point(size = 3)+\n  geom_line(aes(group = Cow_ID),linewidth = 1)+\n  scale_x_continuous(breaks = seq(from = 0, \n                                   to = 14, \n                                   by = 1))+\n  scale_colour_viridis_d(begin = 0.2, end = 0.8)+\n  coord_cartesian(ylim = c(NA, 500))+\n  xlab(\"Milking Number\")+ \n  ylab(\"6′-Sialyllactose (6′SLN) concentration (μg/mL)\")\n  \np_raw\n```\n\nWarning: Removed 18 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 17 rows containing missing values (`geom_line()`).\n\n\n\n\n\nIt seems there’s a couple of individuals who are pretty high, and we might want to take a look. One option is to use interactive plots (see below), or we might want to plot one cow at a time.\nLet’s filter out 1 cow this time, and then re-plot. Notice that all of this code is identical to above, and we just added in a filter step.\n\n```{r}\nsix_SLN %>% \n  filter(Cow_ID == 5716) %>% \n  ggplot(aes(x = Milking, y = six_SLN_conc, colour = Parity))+\n  geom_point(size = 3)+\n  geom_line(aes(group = Cow_ID),linewidth = 1)+\n  scale_x_continuous(breaks = seq(from = 0, \n                                   to = 14, \n                                   by = 1))+\n  scale_colour_viridis_d(begin = 0.2, end = 0.8)+\n  coord_cartesian(ylim = c(NA, 500))+\n  xlab(\"Milking Number\")+ \n  ylab(\"6′-Sialyllactose (6′SLN) concentration (μg/mL)\")\n```\n\n\n\n\nLet’s turn the ggplot part into a function to make it easier for us to re-use:\n\n```{r}\n# create the funciton, this takes a df as input and plots it\n# The function is saved in the environment to re-use\n# \nf_plot_individual <- \n  function(df_in){\n    p <- \n      df_in %>% \n      ggplot(aes(x = Milking, y = six_SLN_conc, colour = Parity))+\n      geom_point(size = 3)+\n      geom_line(aes(group = Cow_ID),linewidth = 1)+\n      scale_x_continuous(breaks = seq(from = 0, \n                                      to = 14, \n                                      by = 1))+\n      scale_colour_viridis_d(begin = 0.2, end = 0.8)+\n      coord_cartesian(ylim = c(NA, 500))+\n      xlab(\"Milking Number\")+ \n      ylab(\"6′-Sialyllactose (6′SLN) concentration (μg/mL)\")\n    \n    return(p)\n  }\n\n\n\n#subset 1 cow of data to plotx\nsubset_data_test <- \n  six_SLN %>% \n  filter(Cow_ID == 5716)\n\n# execute the function\nf_plot_individual(df_in = subset_data_test)\n```\n\n\n\n\nNow we can give any dataframe to our function to plot, even the whole dataframe:\n\n```{r}\nf_plot_individual(six_SLN)\n```\n\nWarning: Removed 18 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 17 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n7.1.1 map\nNow we are going to go back to a similar idea that we saw in split-apply-combine. This time we will be split our data frame into a list, and tell R to iterate through the list of small data frames and each time run our function.\n\n```{r}\n# split our dataframe into a list of small dataframes\nlist_of_dfs <- \n  six_SLN %>% \n  group_by(Cow_ID) %>% \n  group_split()\n```\n\nLet’s check the structure of our list. If we look at the first element in our list, it is a df with 1 cow_ID.\n\n```{r}\nlist_of_dfs[1]\n```\n\n<list_of<\n  tbl_df<\n    Cow_ID       : integer\n    Milking      : integer\n    Parity       : character\n    six_SLN_conc : double\n    six_SLN_yield: double\n  >\n>[1]>\n[[1]]\n# A tibble: 10 × 5\n   Cow_ID Milking Parity six_SLN_conc six_SLN_yield\n    <int>   <int> <chr>         <dbl>         <dbl>\n 1    154       1 MP            74.8          449. \n 2    154       2 MP            14.6           36.5\n 3    154       3 MP             8.70          21.7\n 4    154       4 MP             9.40          94.0\n 5    154       5 MP             8.49         110. \n 6    154       6 MP             5.16          43.8\n 7    154       8 MP             3.93          45.2\n 8    154      10 MP             2.85          28.5\n 9    154      12 MP             2.24          20.2\n10    154      14 MP             1.36          15.0\n\n\nHere we see the second element is the next cow:\n\n```{r}\nlist_of_dfs[2]\n```\n\n<list_of<\n  tbl_df<\n    Cow_ID       : integer\n    Milking      : integer\n    Parity       : character\n    six_SLN_conc : double\n    six_SLN_yield: double\n  >\n>[1]>\n[[1]]\n# A tibble: 10 × 5\n   Cow_ID Milking Parity six_SLN_conc six_SLN_yield\n    <int>   <int> <chr>         <dbl>         <dbl>\n 1   2449       1 MP          140.          1685.  \n 2   2449       2 MP           83.4         1418.  \n 3   2449       3 MP           21.2          339.  \n 4   2449       4 MP            7.02         112.  \n 5   2449       5 MP            3.40          71.3 \n 6   2449       6 MP            2.09          35.5 \n 7   2449       8 MP            1.12          21.2 \n 8   2449      10 MP            0.702         13.7 \n 9   2449      12 MP            0.274          4.92\n10   2449      14 MP           NA             NA   \n\n\nNow, let’s iterate through the first 3 and last 3 in the list and give it to our function\n\n```{r}\npurrr::map(list_of_dfs[c(1:3,18:20)], ~ f_plot_individual(.x))\n```\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 6 rows containing missing values (`geom_line()`).\n\n\n[[1]]\n\n[[2]]\n\n[[3]]\n\n[[4]]\n\n[[5]]\n\n[[6]]"
  },
  {
    "objectID": "advanced_plots.html#interactive-plots-with-plotly",
    "href": "advanced_plots.html#interactive-plots-with-plotly",
    "title": "7  Intro to Advanced Plotting",
    "section": "7.2 Interactive plots with plotly",
    "text": "7.2 Interactive plots with plotly\nMaking interactive plots is easy now that you’re used to using RNotebooks (which are actually producing a .html file that can accommodate interactive plots in your output). This is made even easier because we only need 1 simple function: ggplotly()\nSee here for details on customising output: https://plotly.com/ggplot2/\nOnce we have a ggplot object, we can give it to ggplotly:\n\n```{r}\nplotly::ggplotly(p_raw)\n```"
  },
  {
    "objectID": "advanced_plots.html#correlations",
    "href": "advanced_plots.html#correlations",
    "title": "7  Intro to Advanced Plotting",
    "section": "7.3 Correlations",
    "text": "7.3 Correlations\nWe saw this at the start, but this time it should look a bit easier to understand.\nSee: https://allisonhorst.github.io/palmerpenguins/articles/pca.html\n\n```{r}\npenguins %>%\n  select(species, body_mass_g, ends_with(\"_mm\")) %>% \n  GGally::ggpairs(aes(color = species),\n          columns = c(\"flipper_length_mm\", \"body_mass_g\", \n                      \"bill_length_mm\", \"bill_depth_mm\")) \n```\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\nWarning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\nRemoved 2 rows containing missing values\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\nRemoved 2 rows containing missing values (`geom_point()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "advanced_plots.html#pca",
    "href": "advanced_plots.html#pca",
    "title": "7  Intro to Advanced Plotting",
    "section": "7.4 PCA",
    "text": "7.4 PCA\nThis same link has a good resource for PCA analysis as well: https://allisonhorst.github.io/palmerpenguins/articles/pca.html"
  },
  {
    "objectID": "advanced_plots.html#heatmaps",
    "href": "advanced_plots.html#heatmaps",
    "title": "7  Intro to Advanced Plotting",
    "section": "7.5 Heatmaps",
    "text": "7.5 Heatmaps\nA great package for heatmaps is pheatmap. However it isn’t as well document. See: https://davetang.org/muse/2018/05/15/making-a-heatmap-in-r-with-the-pheatmap-package/\nIt’s particularly useful for larger datasets and exploratory work. This is one example from some gene expression work:\n\n\n\n\n\nThe End."
  }
]